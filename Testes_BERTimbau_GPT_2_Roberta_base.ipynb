{
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Example: Using BERTimbau for Text Embedding (Feature Extraction)\n",
        "\n",
        "This code shows how to get contextual embeddings (vector representations) of a Portuguese sentence using BERTimbau:"
      ],
      "metadata": {
        "id": "Vrkp44lq1ZFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch"
      ],
      "metadata": {
        "id": "qCE5ti1r076Y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311,
          "referenced_widgets": [
            "756e3f67fb0044ac9c30510684b1b0aa",
            "4c74ba9094de45bcbc516c42bd915e1b",
            "61ba3e302d6d42eea83446ce523d407a",
            "5af8bc3c5cf947f289af5e55bd1db47d",
            "03ea80ca1a2844389fcc092b54d6e33d",
            "21b9d33460b14a95a533553e0e87e7d4",
            "1b35f65743e94aae9d528aadd258449d",
            "c19f88105bed4433852a1c1ca0f73931",
            "bcf10f22b7a64bab93630fc49713affe",
            "e0e8d79116ec45a78bdf948fde4769ab",
            "a681e4f56c4d4bf5940140f8cf2edb77",
            "61b967e0edd0433f9d97cad7398b5250",
            "f9db0d826342485e82e8a9adb780f41a",
            "a9986d08229a4492ade3327f2478fd40",
            "68fec7489d544179a9ab059c57ab686b",
            "00e5289d032c4234ad627b5ff492b45b",
            "6bbcd914d98c4834b846b36947374057",
            "8785edd7430b4002ae61ac58061b22f0",
            "3ea545141e42408d8775bd21f6fe2f70",
            "82e8eebbb43948be9c37aaac66e98da1",
            "c0e725c27a534cb19ae7dc64d3d046de",
            "2f97cf7f36db4f8c957230dff2a101ee",
            "e1057fa5c6634a0d8c5f472a7941fb09",
            "37131ba78b084c9f9ce4d78ebfd76ca8",
            "daf77c2af9874a03b26f724f4f095f0d",
            "59520cceea91475981c8d5b804ec9787",
            "42ec5a748b614206be7759607d11af9d",
            "fbd69c1b7afb4083ad2803a52b95e593",
            "d1542a01262f4f44a0de3c97a6708e0a",
            "bbe1290c7b0a4ede916a90d6e97313f4",
            "52e1018d73e84dd3887dc7ffed2aa6b7",
            "d5ca348993ef48e1b456b3db8b99133d",
            "687963e026b74a768a622ad30901003d",
            "301da0ccd8964e6d91fceccff2635ca4",
            "4954350cfc0e4aaa9327c96a897f520d",
            "41964707ed984256a57100969704681b",
            "174bedbfd5b94bec8054640fa59be153",
            "c035adb1db2c4f47b7c02e48f3f12aa1",
            "944b02e5fbc347468c28f799ddcbd5b0",
            "f9e80080eadf45b8806fbfbc92d53b10",
            "338dad99da7a4b0e9d4247610b6ccd62",
            "d5d1860b1c1b401f9f6e0f088a343f00",
            "31ba2cec4ef240538aaeac8aad87d24f",
            "f51d64a8b8c6419380153340b6e28ba7",
            "171304f2c9ec4d9ea47dc40ff8df396c",
            "b81234cf7c81424b8a5ca4b8fd7356bd",
            "a31ab92d0a8a4653aa8367b60f0d8533",
            "97cf68e0fd9c441aa52f287745b91d6e",
            "fb2a84d0438245ff98e7bc53f5ff4d4f",
            "16421586372248019cd2c2bce5ab13df",
            "04761f45d97544f8b35240a5e4ee0b01",
            "e90214d35bcd4901aeacc359fd33712c",
            "2e44cee203ed410897ae2cc08c1b74a9",
            "ac1c80f1f2a4457d87aa529ce6067c46",
            "4672fa4d2d5e4c44b9b84f9a26d33021",
            "c537b606f518473e8a54491685bf3bb8",
            "d8bd9890cb984aee9f5686aca8259f16",
            "49d735d92cbb44aa861e7a5c1df6786c",
            "7aabec433b154699bc993f0991eb8875",
            "ea44b39d7e684b81b23220ea1a277366",
            "50840898ea1e4da0b05b7c1eaeff713f",
            "79c75aca9b6442099723281bcc350271",
            "64de0d7fe6bf4f649f4e316e5945906a",
            "90ed5c54642547e49678aa610f75506c",
            "e10a4e6faabb4454846f6a9f8ecdd141",
            "f4149bbfbdbf4f54b4729ec630830562",
            "464d36b3b17341c6aa755de640b53b06",
            "0080caccb1fd4c2799f7345db4e482a4",
            "ca2b22b980874f8e89651e95c383938e",
            "7dbf83f950f5442c91de18578c2f5d5e",
            "486cd687430b42a79da1267b7ca8bc00",
            "7170384f3c034ec485798402c9db27c0",
            "c9ac807d700a472b80f59ca55058025d",
            "abb1696a57ba46f6963557f9fa12d581",
            "cfd318482d974d62a195d789e66bc86d",
            "4beca52409ce44278137c03269f5e757",
            "3fb10da95e6d4fb39eed1f42f2af151f"
          ]
        },
        "id": "Itkrkknsyl0S",
        "outputId": "ab2550aa-d457-421b-c80c-013ce368c396"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "756e3f67fb0044ac9c30510684b1b0aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61b967e0edd0433f9d97cad7398b5250"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/210k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1057fa5c6634a0d8c5f472a7941fb09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "301da0ccd8964e6d91fceccff2635ca4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "171304f2c9ec4d9ea47dc40ff8df396c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c537b606f518473e8a54491685bf3bb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "464d36b3b17341c6aa755de640b53b06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding shape: torch.Size([1, 768])\n",
            "Embedding (first 5 dims): tensor([ 0.2248,  0.1926,  0.6707, -0.1607,  0.4403])\n"
          ]
        }
      ],
      "source": [
        "# Load BERTimbau model and tokenizer\n",
        "model_name = 'neuralmind/bert-base-portuguese-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Input text in Portuguese\n",
        "text = \"Qual é a capital do Brasil?\"\n",
        "\n",
        "# Tokenize and encode the text\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Get model output (no gradients needed for inference)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Extract the embeddings (CLS token or mean pooling)\n",
        "last_hidden_states = outputs.last_hidden_state\n",
        "embeddings = last_hidden_states.mean(dim=1)  # Mean pooling\n",
        "\n",
        "print(\"Embedding shape:\", embeddings.shape)  # [1, 768]\n",
        "print(\"Embedding (first 5 dims):\", embeddings[0, :5])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example: Using BERTimbau for Question Answering (QA)\n",
        "\n",
        "If you want to use BERTimbau for question answering, you need a fine-tuned QA model. Here’s an example using a Portuguese QA model (if available):"
      ],
      "metadata": {
        "id": "dFDTaOP51ldq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "p-znHySn1r4O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a Portuguese QA model (if fine-tuned)\n",
        "qa_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=\"neuralmind/bert-base-portuguese-cased\",\n",
        "    tokenizer=\"neuralmind/bert-base-portuguese-cased\"\n",
        ")\n",
        "\n",
        "context = \"\"\"\n",
        "O Brasil é um país localizado na América do Sul. Sua capital é Brasília,\n",
        "que foi planejada pelo arquiteto Oscar Niemeyer. O idioma oficial é o português.\n",
        "\"\"\"\n",
        "\n",
        "question = \"Qual é a capital do Brasil?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "print(\"Answer:\", result[\"answer\"])  # Output: \"Brasília\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVBuwMLH1kHt",
        "outputId": "7c4e861b-e533-465e-c1f7-759063edad07"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: na América do Sul. Sua\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example: Using BERTimbau for Text Classification\n",
        "\n",
        "If you want to classify text (e.g., sentiment analysis in Portuguese):"
      ],
      "metadata": {
        "id": "cweLGlP12HMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a Portuguese text classification model (if fine-tuned)\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"neuralmind/bert-base-portuguese-cased\",\n",
        "    tokenizer=\"neuralmind/bert-base-portuguese-cased\"\n",
        ")\n",
        "\n",
        "result = classifier(\"Eu amo programar em Python!\")\n",
        "print(result)  # Output: [{'label': 'POSITIVE', 'score': 0.98}]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKTapZ6g2IVr",
        "outputId": "34e86fb8-2881-4961-e679-c57732bbe8aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'LABEL_1', 'score': 0.5156468749046326}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using GPT-2 fine-tuned for Portuguese (specifically the pierreguillou/gpt2-small-portuguese model) to generate text in Portuguese."
      ],
      "metadata": {
        "id": "6nZzWzNm3x75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_BUK2SQ43zkp",
        "outputId": "763042f6-be6f-4fb9-ca49-55cd166a6148"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "19985e5e52b5414e8ae3e7cf2ee2713e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Text Generation Example\n",
        "\n",
        "This example generates Portuguese text from a prompt:"
      ],
      "metadata": {
        "id": "V7f509lY5_1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch"
      ],
      "metadata": {
        "id": "ymG2cqiW4bmc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Portuguese GPT-2 model and tokenizer\n",
        "model_name = \"pierreguillou/gpt2-small-portuguese\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Input prompt in Portuguese\n",
        "prompt = \"O futuro da inteligência artificial no Brasil\"\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate text (adjust max_length and temperature as needed)\n",
        "outputs = model.generate(\n",
        "    inputs.input_ids,\n",
        "    max_length=100,  # Maximum length of generated text\n",
        "    num_return_sequences=1,  # Number of responses to generate\n",
        "    temperature=0.7,  # Controls randomness (lower = more deterministic)\n",
        "    do_sample=True,  # Enable sampling\n",
        ")\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360,
          "referenced_widgets": [
            "14f5292694c9465ea09cc62a051f1b16",
            "ceee22ede5894da69a0b30cf6515214f",
            "7157fd47dd594d74bc1ec8a2b4c91ddc",
            "40f577d27bf34ebcbc5469377e4bf285",
            "3767f7c73c704af4bd43c8fb033f0dc6",
            "3cde7cd482b94a63a8d26fbc42d11370",
            "2b108aede6da4549acb72bdb135d49de",
            "a78fc0d2ad5941059adc8798033ba9b4",
            "75976ae09cc94aefb9c673c33311cec2",
            "7461a444bf0e42f297d704e91f66e450",
            "ecec59098f124d2b8dd99537f53fdddd",
            "f2bf4153216a464380db8abe1f40313d",
            "acddb5e8f7ce40a2a4ab32fe9000ea03",
            "8d381af5c5974f348435c630cca7ff9f",
            "97b450bb0ebf4143b1631e33227e93ad",
            "c48eef39d09949568ef436bcf2744b62",
            "76d7d4a597f642cdb07ea26caa7a35e7",
            "ddce5f9a23ba44019417e70568802177",
            "ed7e4c7b40ae4f33af7bd3525430eeaf",
            "bf6e3f669d824c7395a812d9dd1b6a59",
            "9482b3c9ebf049318f8e76c76b1327b9",
            "c9381f6c9af04193a07335121fc8643f",
            "29b56f14b23846a793330860407daa8a",
            "12d7789758264e8e872fedb553cae17d",
            "f57ad4aeebb94573b101ab3f9b957509",
            "fcceece8301148bc895d6697253b0d3d",
            "db78469c5efa473aa5c0ff81b4a5f5a4",
            "6a925c4ed8e04d7395bba0d80a6b6e5d",
            "0c954e650ac0481d8e58ff1178578a83",
            "29b7c2e1b8a942e6b1466f7b36a0eaed",
            "3ea6e451021445459d1dc1a0eb7be459",
            "c1c0d4405f3b478596ff8a7c1f3838f7",
            "c704c6056593497c8a27c71a30efb702",
            "b9801029b82a460fa94fa7e901fbbb24",
            "00d20c1386d747a99a0cb94486820db9",
            "7e1f7a0587174feb8b113294befa78c6",
            "fb8f4a3fc9d74852b9d37586e880abca",
            "936a5c995429460eab10db6a51075b2f",
            "9587da0d775b4b31abd4b57b2f1b6e42",
            "64952b3643374314b4f0bcca0817db83",
            "5a4376c25fc54afb819f5b31ad1e5378",
            "64eb80f3e787456bb1173f64e0dd26e6",
            "88a14446b6164c02abde20fea6af32f3",
            "a743e91019c94f65b195953ec25a7673",
            "a84a0d9826c54a34a9392e84efc7d790",
            "9f832855e0e5444c907baff85fbf5272",
            "5c2c1390bec043c98315091075b3fdc4",
            "f0f1bee6e5fa49f1b7440ef775b182b8",
            "d777dfca28a048aa9e9a82d1be2beb22",
            "052d4b219f1f465cb0f687178a098b66",
            "fb97efc94a2f4ad2a18be0b1a7bfa58f",
            "821dc6b73b024d6b866b5e74c072896b",
            "43cd0f838c3c4ae4929c92758bf57a0e",
            "f16a43cb017646939139b2d32f0eb6ed",
            "47644421e9cf45528023348195380713",
            "76b9a83198a543bfa4a91437fd653be5",
            "03795b91a1be456abfe663bc7105374a",
            "bc272fd0f5d84f7ba0c6449c3ccf7c5d",
            "b40e960e975f4f27ac65f4a3e095adf2",
            "c1cffaee6cf845918597959dfe18a446",
            "eb039ae8d2d34a749b033f899c8e1a54",
            "42e04d2635a14ce6903e4fe3466c032a",
            "33fdbc9f898342858bf108e9508d87c9",
            "001958c20d4647d4a551005335bfc68e",
            "d3c9b81f86554933888bf6455131de84",
            "55dde235d2db4666aa75a20bcd5a7c56",
            "9fdb7b36f8cd45eebe8309e85c88d942",
            "fee2b818a74544c191b41dcd04ae6bd7",
            "e9eb28407bbe454a96255e1318fec043",
            "f6042e6a89874e56ac151371ba2ed75e",
            "22d2a74cb5284e6d9d5fe063e25ae283",
            "0d51bbe49eb548ae882ced515b684190",
            "fa5c19fe30174998a792ec67dd8226f2",
            "4b3facf22a0144c0a345b6ec48a8adbb",
            "d4c739c42a2440e19fd51ccf132ee5bb",
            "2d3231d89556489e97e299d29a38acc4",
            "87334cd8a2bc46409f2bb605282e87a3"
          ]
        },
        "id": "-dLzZHFb38Vh",
        "outputId": "445fd46b-d246-4763-ee2f-e06f9fc52a4e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/92.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14f5292694c9465ea09cc62a051f1b16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2bf4153216a464380db8abe1f40313d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/850k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29b56f14b23846a793330860407daa8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/508k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9801029b82a460fa94fa7e901fbbb24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a84a0d9826c54a34a9392e84efc7d790"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76b9a83198a543bfa4a91437fd653be5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/510M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fdb7b36f8cd45eebe8309e85c88d942"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O futuro da inteligência artificial no Brasil é incerto. Algumas teorias sugerem que o Brasil tenha se desenvolvido através de técnicas avançadas, como computadores pessoais, redes de computadores e redes de fibra de carbono. Outras teorias sugerem que as tecnologias atuais poderiam ser desenvolvidas mais rapidamente, com a tecnologia atual sendo capaz de atingir grandes distancias, como a capacidade de se comunicar em alta velocidade.\n",
            "\n",
            "Uma das maiores preocupações sobre a tecnologia atual é o fato de que, embora haja um crescimento significativo no número de robôs e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Generation with Custom Settings\n",
        "\n",
        "You can tweak generation parameters for more control:"
      ],
      "metadata": {
        "id": "WwlbdtaX6EVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(\n",
        "    inputs.input_ids,\n",
        "    max_length=150,\n",
        "    num_return_sequences=3,  # Now works with sampling\n",
        "    temperature=0.9,        # Higher = more creative/random\n",
        "    top_p=0.95,             # Nucleus sampling (keep top 95% of probable tokens)\n",
        "    do_sample=True,         # Critical for multiple sequences\n",
        ")\n",
        "\n",
        "for i, output in enumerate(outputs):\n",
        "    print(f\"\\n--- Generated Text {i+1} ---\")\n",
        "    print(tokenizer.decode(output, skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARlc-ba74pxU",
        "outputId": "231272db-262f-4463-edb2-e58bcc7c036d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generated Text 1 ---\n",
            "O futuro da inteligência artificial no Brasil deve entrar em um momento de grande desenvolvimento.\n",
            "\n",
            "A ideia de um futuro em que o homem, ao invés de ficar em silêncio, possa comunicar-se com os outros em tempo real, uma forma de gerar conhecimento para os outros, foi introduzida pelo psicólogo e cientista brasileiro Renato Magalhães.\n",
            "\n",
            "Meses depois, o jornalista Luiz Felipe Castro chegou ao Brasil, para criar o primeiro aparelho de comunicação na cidade, para estudar os pensamentos de um indivíduo, assim como desenvolver um aparelho de comunicação.\n",
            "\n",
            "O projeto veio à luz com a participação de Maurício Tavares, diretor do Centro de Pesquisas da Universidade Federal de São Paulo (UFSP), que realizou o primeiro experimento da vida em rede e foi contratado em parceria com\n",
            "\n",
            "--- Generated Text 2 ---\n",
            "O futuro da inteligência artificial no Brasil deve ser definida por meio da análise de inteligência artificial.\n",
            "\n",
            "A análise da inteligência artificial será desenvolvida no Brasil, e a inteligência artificial é usada em todo o mundo. A análise da inteligência artificial pode ser utilizada para melhorar a gestão do governo no Brasil e em todo o mundo. A inteligência artificial usa inteligência artificial para melhorar o atendimento ao público, mas também em casos de doença grave, saúde ou morte, como por exemplo na investigação de casos de assassinato e de suicídio.\n",
            "\n",
            "No Brasil, o Brasil é o país que mais desenvolve a inteligência artificial.\n",
            "\n",
            "Em Portugal, a ciência e tecnologia desenvolveu-se em vários ramos, cada um deles levando a novas formas de trabalhar para diferentes áreas da ciência e tecnologia\n",
            "\n",
            "--- Generated Text 3 ---\n",
            "O futuro da inteligência artificial no Brasil está em curso. O primeiro dos dispositivos de inteligência artificial da história, projetado e construído pela União de Pesquisa e Desenvolvimento de Massachusetts (Upp) e baseado na tecnologia desenvolvida em parceria com a AIBA, está em curso. A máquina irá fornecer informações aos seres humanos e com eles, a partir de uma técnica que irá, a cada dia, aumentar o conhecimento e inteligência das pessoas.\n",
            "\n",
            "A iniciativa de desenvolver a máquina é uma iniciativa da IBM. Em 2014, a IBM anunciou que o sistema, baseado no IBM PC, seria o \"Novo Oriente\" e foi lançado em 2015, no aniversário do 25º aniversário da IBM. A IBM é conhecida pelo seu programa \"Innovative Computing System\",\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load model\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"pierreguillou/gpt2-small-portuguese\",\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Test directly\n",
        "prompt = \"O futuro da inteligência artificial no Brasil\"\n",
        "output = generator(\n",
        "    prompt,\n",
        "    max_length=100,\n",
        "    temperature=0.7,\n",
        "    do_sample=True\n",
        ")\n",
        "\n",
        "print(\"Generated Text:\")\n",
        "print(output[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jiwD-eKA994",
        "outputId": "29e7673c-df1b-4a60-9ff7-e9762b92a99b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "O futuro da inteligência artificial no Brasil (principalmente em relação à tecnologia avançada) é incerta, apesar das previsões de que a inteligência artificial será usada para melhorar o ambiente em todos os países.\n",
            "\n",
            "O conceito de inteligência artificial no Brasil foi desenvolvido pela iniciativa privada brasileira no final de 2015. Em novembro de 2015, o cientista político e ambiental Carlos Chagas, pesquisador da Universidade Federal do Rio de Janeiro (UFRJ) e da Universidade de São Paulo (USP), apresentou seu projeto de Inteligência Artificial no Congresso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using API by FastAPI"
      ],
      "metadata": {
        "id": "lO_1OgkH-YXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install fastapi uvicorn nest-asyncio pyngrok\n",
        "#!pip install fastapi transformers torch uvicorn nest-asyncio\n",
        "!pip install fastapi transformers torch uvicorn nest-asyncio requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhtHMSIt-Pr9",
        "outputId": "58c53afa-8015-4f04-d106-f736c384e10a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from transformers import pipeline\n",
        "import nest_asyncio\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import threading\n",
        "import uvicorn\n",
        "import requests\n",
        "import time"
      ],
      "metadata": {
        "id": "kciszEHoBXEL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the app\n",
        "app = FastAPI()\n",
        "\n",
        "# Add CORS middleware\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Load the model\n",
        "print(\"Loading model...\")\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"pierreguillou/gpt2-small-portuguese\",\n",
        "    tokenizer=\"pierreguillou/gpt2-small-portuguese\",\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "print(\"Model loaded!\")\n",
        "\n",
        "class Request(BaseModel):\n",
        "    prompt: str\n",
        "    max_length: int = 100\n",
        "\n",
        "@app.post(\"/generate\")\n",
        "def generate_text(request: Request):\n",
        "    response = generator(\n",
        "        request.prompt,\n",
        "        max_length=request.max_length,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "    )\n",
        "    return {\"generated_text\": response[0][\"generated_text\"]}\n",
        "\n",
        "@app.get(\"/generate_test\")\n",
        "def generate_test(prompt: str = \"O futuro da IA no Brasil\", max_length: int = 100):\n",
        "    response = generator(\n",
        "        prompt,\n",
        "        max_length=max_length,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "    )\n",
        "    return {\"generated_text\": response[0][\"generated_text\"]}\n",
        "\n",
        "# Function to run the server\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1KikEdJBSpV",
        "outputId": "7583fba1-6567-45d6-fad4-8807e69329ed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the server in a background thread\n",
        "print(\"Starting server...\")\n",
        "nest_asyncio.apply()\n",
        "thread = threading.Thread(target=run_server, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "# Wait for server to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Now test the API\n",
        "print(\"\\nTesting API...\")\n",
        "test_prompt = \"A importância da inteligência artificial\"\n",
        "response = requests.post(\n",
        "    \"http://localhost:8000/generate\",\n",
        "    json={\"prompt\": test_prompt, \"max_length\": 100}\n",
        ")\n",
        "\n",
        "print(f\"\\nPrompt: {test_prompt}\")\n",
        "print(\"Generated Text:\")\n",
        "print(response.json()[\"generated_text\"])\n",
        "\n",
        "print(\"\\nServer is running in background. You can make more requests!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_XWB_i2Bpkl",
        "outputId": "90f07319-500b-41d5-ab0e-87176c74dd97"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting server...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [4077]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing API...\n",
            "INFO:     127.0.0.1:45484 - \"POST /generate HTTP/1.1\" 200 OK\n",
            "\n",
            "Prompt: A importância da inteligência artificial\n",
            "Generated Text:\n",
            "A importância da inteligência artificial, da inteligência artificial e da inteligência artificial como um campo de trabalho para os cientistas da área de ciência e tecnologia, e a necessidade de se envolver, nos anos de 1990, com os governos, a Agência Nacional de Energia Atômica, e o Instituto de Energia Atômica, foi muito debatida.\n",
            "\n",
            "Em 1998, o programa de computador quântico-fluidação de campo da NASA foi chamado de \"Programa de Pesquisa de Fluidação de Energia Atômica\". O\n",
            "\n",
            "Server is running in background. You can make more requests!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.post(\n",
        "    \"http://localhost:8000/generate\",\n",
        "    json={\"prompt\": \"A importância da educação\", \"max_length\": 100}\n",
        ")\n",
        "print(response.json())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-nIe2GS6OMd",
        "outputId": "1d7f7484-e2c4-42b1-cb74-6b883c75e0fb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55798 - \"POST /generate HTTP/1.1\" 200 OK\n",
            "{'generated_text': 'A importância da educação no mundo ocidental é enorme. Muitos países ocidentais consideram a educação a maior fonte de motivação para o progresso. Um estudo de 1998 do Instituto de Pesquisas Chinesas (IUPER) concluiu que os países ocidentais com o maior índice de alfabetização têm uma taxa de 14,7% de alfabetização a cada dez anos. Em 2005, o estudo de alfabetização da Europa Oriental, liderado pelo professor de educação física e informática Hans-Joachim Söder, e publicada em 2008 pela revista \"'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! curl -X POST \"http://localhost:8000/generate\" \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-d '{\"prompt\":\"A importância do uso inteligência artificial nos cursos de ciência da computação\",\"max_length\":500}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1N_HwUTA-xO",
        "outputId": "26d2d499-0723-4fdd-82e2-ec74d76c9ca4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39844 - \"POST /generate HTTP/1.1\" 200 OK\n",
            "{\"generated_text\":\"A importância do uso inteligência artificial nos cursos de ciência da computação é largamente discutida, devido ao fato de que o uso de inteligência artificial não é um campo de pesquisa acadêmica.\\n\\nA computação é uma ciência de computação altamente dinâmica e possui várias aplicações em diversas áreas como medicina e ciência da computação, engenharia, medicina, ciências da computação, engenharia de sistemas e engenharia de sistemas.\\n\\nAnálise de dados, análise de dados, análise de dados, análise de dados, análise de dados em nuvem, análise de dados em nuvem, análise de dados em nuvem e análise de dados em nuvem são alguns dos aspectos de análise de dados utilizados no ensino de computação, principalmente a análise de dados em nuvem.\\n\\nA análise de dados é realizada através do uso de técnicas de programação dinâmica e de redes para analisar, analisar e resolver problemas de forma eficiente através de algoritmos.\\n\\nUm dos principais problemas da análise de dados é o de como o modelo ou o modelo de dados interage com outros sistemas para resolver problemas.\\n\\nO objetivo é encontrar as relações entre os dados e seus estados de validade.\\n\\nUm problema de análise de dados envolve a análise de dados sem o uso de técnicas de programação dinâmica.\\n\\nUm problema de análise de dados envolve a análise de dados em redes de computadores.\\n\\nUm problema de análise de dados envolve análise da informação em rede e os algoritmos que atuam em rede para resolver problemas.\\n\\nUm problema de análise de dados envolve análise de dados em redes de computadores.\\n\\nUm problema de análise de dados envolve análise de dados em redes de computadores e os algoritmos que atuam em rede para resolver problemas.\\n\\nUm problema de análise de dados envolve análise de dados em redes de computadores e os algoritmos que atuam em rede para resolver problemas.\\n\\nUm problema de análise de dados envolve análise de dados em redes de computadores.\\n\\nUm problema de análise de dados envolve análise de dados em redes de computadores.\\n\\nUm problema de análise de dados envolve análise de dados em redes de computadores.\\n\\nUm problema de análise de dados envolve análise de dados em redes de computadores.\\n\\nUm problema de análise de dados envolve análise de dados em redes de computadores.\\n\\nUm problema de análise de dados envolve análise de dados em redes de computadores.\\n\\nUm problema de análise de dados envolve análise de dados em redes de computadores.\\n\\nUm problema de análise de dados envolve análise de dados em redes de computadores.\\n\\nUm problema de análise de dados envolve análise\"}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using wikipedia dataset (simple)"
      ],
      "metadata": {
        "id": "RmslXkqPT1l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Primeiro instale os pacotes necessários\n",
        "!pip install datasets transformers torch sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7omC-n0QUf3m",
        "outputId": "1de24303-d581-454e-9dee-fdd4e1455036"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "import re"
      ],
      "metadata": {
        "id": "pr-QIQoBUhiC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura o modelo de Q&A\n",
        "qa_model = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=\"deepset/roberta-base-squad2\",\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "4104b3be79ca4a85bca7208352522ec4",
            "bdaa2e32b865467db83b0390b94fb1db",
            "e7eaaa3ebb0540a78f977bd42f2459ea",
            "c98caa17b4c34a72a322c6bb93245a49",
            "8b2d546b9cd1434ebef5d1403d236b76",
            "e5a88e311eb948bca1c3c1ff171b4725",
            "72f786f398b341d59dc2aa021bcb26c9",
            "86b00cf4f760408c92d899f64f263f23",
            "eb9eba61de364a818424490dd9d72903",
            "371b279161074c77b3d00faf20f61c74",
            "fc8fdf143e2f4a1387ef8449706b789d",
            "14a5de9e40d14d48a343ff9b6466a568",
            "af749643fe884fa392e0f9c834e98698",
            "4c3ce9ab52f04f26b3bc50a14b364f78",
            "0395bda736ba4c0f9c16752872a2e5a4",
            "3e51dc449c71487abc2e5e09ca9d8c16",
            "95d90e347ff34ec6ba77cb6f4861f297",
            "10179b1157784e64b69ed89b88078635",
            "6c1915e77b984c1ba97b99f2de8ef4ea",
            "4d0947117a33405e8f1012a560fdcb55",
            "86c7a6a0d596431f84776376f6e0c899",
            "c4456202aa95429688806041d8ca063a",
            "cbc9f82deb8441a4b15b8dd3f3d1b6ce",
            "872131a7947246d0a89197ea12a8281e",
            "ebda4655e9854d9bbed934df960a1548",
            "42a36067691d452d8e48a8942c0f0691",
            "0f19e3f5f1c141c2a172c3f0ce01b21e",
            "6eaddcfedfac4289a91ec98feb7bc08e",
            "eaacdb7e770d41b7b10997ac2d421959",
            "1f413d9bd00f4d609aece792d63a10ac",
            "bd04211e43e34bf9a9f1b226b11ea302",
            "fe26c4a9580e495b9952ab03f228f2c7",
            "8f9a370d661b466f9ff49032fa43b3a2",
            "2e6e9416e6134ac58bbed0256c898100",
            "1e940b38ec5f49de82195e910990a007",
            "52a581ed4ca14e24b5e3d50e0c0a75a6",
            "259aa46f3f094c1684bbf657d33a2584",
            "a3219fd041cf48baa968bb05742fd80b",
            "22ee82ad61dc4a1da65f509f029bf2ac",
            "c3ae282a184e477f90539b510beb5a58",
            "f4bf5e8d34734925a430b72c7ba6cce8",
            "1fc748ef44fb416096ae884d1f054165",
            "ccc19056ff224dcbb02feed67e1d9e09",
            "aa8f25d667634f8ea398de58ce03e25e",
            "bc316db28d8f44f79e8ca8a42ac3d5a9",
            "3829b54d62594724a658e690db4a9e62",
            "ca9f50f4ee54492a96532e9880978546",
            "1f748aea457e47b0a5183de85a9accfb",
            "71e110dadaf14ae5afb1a879be993d51",
            "774fc721b6714539ab856b28376143ba",
            "f09d5194b2e9465d8f499a6d5d66f988",
            "440eb87434b145f2865b7055a54c9878",
            "b13fcb42cf8b4213aed4b6b8b4180f7d",
            "7515ae44b8b94ac6a559e4d8d4ebcc76",
            "344e7642d26448ec9eb72520974c1df8",
            "50e53e9157da4d73a0d0d0442922989d",
            "4739dff0131c4b77900c6526265f91da",
            "3207faabd95f48e6a0105a2d1b46a48c",
            "940f392b61f143629317a6f943e8797f",
            "b34ed9a2918241be8714aa76182b90ea",
            "fc86ff3767764e2292a24d4bf7c3f0c5",
            "f8c80ff66b1a4ae4a9acbdc3a2d5dcc0",
            "ec23b5b58f314fee8bbbf88fe25a80dd",
            "cf2fa8bf73034adb8e0d1eeee3fec7ad",
            "c815709bbb7b442ca06a92dd051c5141",
            "160dbcfba31a459d8a6ab9f3b2b26938"
          ]
        },
        "id": "-ExoRjr9bHzx",
        "outputId": "62a84395-9625-4401-ab6a-57829a366d06"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4104b3be79ca4a85bca7208352522ec4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14a5de9e40d14d48a343ff9b6466a568"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbc9f82deb8441a4b15b8dd3f3d1b6ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e6e9416e6134ac58bbed0256c898100"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc316db28d8f44f79e8ca8a42ac3d5a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50e53e9157da4d73a0d0d0442922989d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset Wikipedia (versão simples em inglês)\n",
        "try:\n",
        "    print(\"Carregando dataset Wikipedia...\")\n",
        "    wikipedia = load_dataset(\"legacy-datasets/wikipedia\", \"20220301.simple\", split='train[:5000]')  # Carrega apenas 5000 artigos para demonstração\n",
        "    print(f\"Dataset carregado com {len(wikipedia)} artigos\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao carregar dataset: {e}\")\n",
        "    raise\n",
        "\n",
        "# Configurar pipeline de Pergunta-Resposta\n",
        "try:\n",
        "    print(\"\\nConfigurando modelo de Q&A...\")\n",
        "    qa_pipeline = pipeline(\n",
        "        \"question-answering\",\n",
        "        model=\"deepset/roberta-base-squad2\",\n",
        "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao carregar modelo: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314,
          "referenced_widgets": [
            "de82db79905849859020e8d21f871cc0",
            "785d9ca563f5463da7e5392f7ac7b17c",
            "ccdbf129d7884fc889a04a54eef48415",
            "3f91125d20eb40868e84478c2745beec",
            "b06bd8711d344726a2d09d8569898376",
            "febea761c7f84ec2a95c25df86dc4da6",
            "fbf6e6be098346049a3eba69d7f01eee",
            "a7ee6d18a7cf4ac29a4dacb2a03f6655",
            "92313942413f4b4cb78e8846de76d665",
            "7806d60c5617461995412b006b2cd985",
            "177ce0538be640a0ba1965154dc30de5",
            "104ee93aeefa4ba583e08f32fc716824",
            "dad4c28b2d7c4bf0966e5f17523889a0",
            "24b3256700af436ea94099c9db42c03f",
            "e4ee8f9238b44602a8af1b02e44b988b",
            "0cea191ce3f443dab7535014fb5b05e4",
            "b471a0007af741e9be5b4453167a3dea",
            "52276a6c0f764ca4b3b2db70793b1f2a",
            "ca0e1e60142646818ca6954994b9838a",
            "9b05758960b245ff8bad1d8b1f197750",
            "b0fca834b77b4563b4a72458763c3aeb",
            "2c205d2e6ac2449d9c18cac6f27c5b4b",
            "b1a87b11faae41ae8d83bec9e7047d01",
            "fda6a509991c4ec8b2a21a0c51edc806",
            "a7015f2d316a49c3aeca7828393f9898",
            "d2375d4d5af9475898eb0353f2d69f56",
            "0db3fca61cee40fb86e8ef9194782e5f",
            "bbcce655411649aab5707496347f4d6f",
            "51541c6896b14e4bb7f06eda5725c00e",
            "9930a3c1b41549a88197d68cb57428a5",
            "bc92f7df87aa4b56b19abb4416cdf442",
            "dcfe25ec66124556a358d745bf73c98a",
            "178c22675a514cc9bb461072ac3f499b",
            "a2ab9255c49d401097a4fdd1132b714a",
            "5d885a79531f44be840a8ff512441141",
            "d4bccbcf5f9d4d86972f67937524ae77",
            "926b549a0a3c49dbbcf56b377493141e",
            "4da6c8f01a87460eb2b2b6bd5f17b461",
            "a9a6a12ed34947eab1be06521d176a47",
            "88c5314890a946889478a7267064a1d6",
            "14fbd7eb167b48acae9fbf0a6561e0ed",
            "2111a2aeaf984c9dbb96d39eb94f2dad",
            "3101c906fdf747f7af8889c1bbf235b5",
            "f22912a7fef945b8ac3b212796a50419"
          ]
        },
        "id": "O5lOOz1bU9n4",
        "outputId": "84c92465-afb3-494e-9028-e084ba45795d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando dataset Wikipedia...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/16.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de82db79905849859020e8d21f871cc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "wikipedia.py:   0%|          | 0.00/36.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "104ee93aeefa4ba583e08f32fc716824"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for legacy-datasets/wikipedia contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/legacy-datasets/wikipedia.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/134M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1a87b11faae41ae8d83bec9e7047d01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/205328 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2ab9255c49d401097a4fdd1132b714a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset carregado com 5000 artigos\n",
            "\n",
            "Configurando modelo de Q&A...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_wikipedia(question, num_articles=1):\n",
        "    # Padrão de retorno consistente\n",
        "    default_response = {\n",
        "        'resposta': \"Resposta não encontrada\",\n",
        "        'confianca': 0.0,\n",
        "        'titulo': \"\",\n",
        "        'contexto': \"\"\n",
        "    }\n",
        "\n",
        "    # Busca artigos com palavras-chave da pergunta\n",
        "    keywords = set(word.lower() for word in re.findall(r'\\w+', question) if len(word) > 1)\n",
        "    relevant_articles = []\n",
        "\n",
        "    for article in wikipedia:\n",
        "        text_lower = article['text'].lower()\n",
        "        if any(keyword in text_lower for keyword in keywords):\n",
        "            relevant_articles.append({\n",
        "                'title': article['title'],\n",
        "                'text': article['text']\n",
        "            })\n",
        "            if len(relevant_articles) >= num_articles:\n",
        "                break\n",
        "\n",
        "    if not relevant_articles:\n",
        "        return default_response\n",
        "\n",
        "    # Tenta extrair resposta dos artigos relevantes\n",
        "    best_answer = default_response\n",
        "    for article in relevant_articles:\n",
        "        #context = ' '.join(article['text'].split()[:1000])  # Limita o contexto\n",
        "        context = ' '.join(article['text'].split())\n",
        "        try:\n",
        "            result = qa_model(question=question, context=context)\n",
        "            if result['score'] > best_answer['confianca']:\n",
        "                best_answer = {\n",
        "                    'resposta': result['answer'],\n",
        "                    'confianca': result['score'],\n",
        "                    'titulo': article['title'],\n",
        "                    'contexto': context[:300] + \"...\"\n",
        "                }\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    return best_answer"
      ],
      "metadata": {
        "id": "a_865QweVJV0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso\n",
        "#pergunta = \"What is the fourth month of the year in the julian and gregorian calendars?\"\n",
        "pergunta = \"Does it April always begins on the same day of week as July?\"\n",
        "resposta = ask_wikipedia(pergunta)\n",
        "\n",
        "print(f\"\\nPergunta: {pergunta}\")\n",
        "print(f\"Resposta: {resposta['resposta']}\")\n",
        "print(f\"Confiança: {resposta['confianca']:.2f}\")\n",
        "print(f\"Artigo: {resposta['titulo']}\")\n",
        "print(f\"Contexto: {resposta['contexto']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iVOQkjvJXfC",
        "outputId": "a0c1411f-31e7-4241-bf20-5dca5db66833"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pergunta: Does it April always begins on the same day of week as July?\n",
            "Resposta: April always begins on the same day of week as July\n",
            "Confiança: 0.10\n",
            "Artigo: April\n",
            "Contexto: April is the fourth month of the year in the Julian and Gregorian calendars, and comes between March and May. It is one of four months to have 30 days. April always begins on the same day of week as July, and additionally, January in leap years. April always ends on the same day of the week as Decem...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perguntas = [\n",
        "    \"What is april ?\",\n",
        "    \"Who wrote Romeo and Juliet?\",\n",
        "    \"How does photosynthesis work?\",\n",
        "    \"When was the internet created?\"\n",
        "]\n",
        "\n",
        "for pergunta in perguntas:\n",
        "    resposta = ask_wikipedia(pergunta)\n",
        "    print(f\"\\nPergunta: {pergunta}\")\n",
        "    if resposta['confianca'] > 0.1:\n",
        "      print(f\"Resposta: {resposta['resposta']} (Confiança: {resposta['confianca']:.3f})\")\n",
        "    else:\n",
        "      print(f\"Sem resposta, pois o nível de confiança é: {resposta['confianca']:.3f}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ufwXEdtW8iK",
        "outputId": "8f6a357a-f6d5-4977-a770-c3e8a25994dd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pergunta: What is april ?\n",
            "Resposta: a spring month in the Northern Hemisphere (Confiança: 0.193)\n",
            "--------------------------------------------------\n",
            "\n",
            "Pergunta: Who wrote Romeo and Juliet?\n",
            "Sem resposta, pois o nível de confiança é: 0.002\n",
            "--------------------------------------------------\n",
            "\n",
            "Pergunta: How does photosynthesis work?\n",
            "Sem resposta, pois o nível de confiança é: 0.001\n",
            "--------------------------------------------------\n",
            "\n",
            "Pergunta: When was the internet created?\n",
            "Sem resposta, pois o nível de confiança é: 0.000\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}