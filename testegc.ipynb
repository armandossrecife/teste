{
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armandossrecife/teste/blob/main/exemplos_openai_gemini_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk7kfZic0KZi",
        "outputId": "982ca8f3-81c4-4e3a-ffb0-cf6126ca2ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.0.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.4 (from langchain)\n",
            "  Downloading langchain_core-1.0.4-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting langgraph<1.1.0,>=1.0.2 (from langchain)\n",
            "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (0.4.41)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (4.15.0)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
            "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
            "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.4->langchain) (3.0.0)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain)\n",
            "  Downloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
            "Downloading langchain-1.0.5-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.8/93.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.0.4-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.2/471.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.2-py3-none-any.whl (34 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "Successfully installed langchain-1.0.5 langchain-core-1.0.4 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.2 langgraph-sdk-0.2.9 ormsgpack-1.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voFBE31f0sQV",
        "outputId": "3fac9ea0-e14f-4d43-b15e-b550b89f0b41"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.0.4)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.41)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.0.2-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch .env"
      ],
      "metadata": {
        "id": "7jROx73I0tRE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlXdo_6R0-Gi",
        "outputId": "a3cc676e-5027-4312-ded8-230dbf3da1de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUuyVToD6vH5",
        "outputId": "f463c82e-9228-4eaf-93ad-9be0eac96065"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langchain                                1.0.5\n",
            "langchain-core                           1.0.4\n",
            "langchain-openai                         1.0.2\n",
            "langchain-text-splitters                 0.3.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-EotNMlS8TqL",
        "outputId": "75645c2c-a41f-416b-d44d-ee0cd47cbd8e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-3.0.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<1.0.0,>=0.7.0 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.0.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.10)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.28.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.4.41)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.32.4)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-3.0.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.9.0 langchain-google-genai-3.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "6b4fbc3147f8442294be0c8b41536334"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# arquivo: teste_openai_api.py\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "# Carrega variáveis do .env (contendo OPENAI_API_KEY)\n",
        "load_dotenv()\n",
        "\n",
        "# Inicializa o cliente OpenAI (pega a chave automaticamente do ambiente)\n",
        "client = OpenAI()\n",
        "\n",
        "# Define o prompt (usuario)\n",
        "prompt = (\"Explique o que é IA Generativa.\")\n",
        "\n",
        "# Faz a requisição ao modelo\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",   # ou \"gpt-5\" se tiver acesso\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Você é um cientista da computação. Responda de forma clara, técnica e objetiva. Limite a saída a ~300 palavras.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature=0.4,\n",
        "    max_tokens=600\n",
        ")\n",
        "\n",
        "# Exibe o resultado\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyDI58gc69oP",
        "outputId": "38f90805-0b39-44a9-b6eb-90856241566d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Inteligência Artificial Generativa (IA Generativa) refere-se a um subcampo da inteligência artificial que se concentra na criação de novos conteúdos, como texto, imagens, áudio e vídeo, a partir de dados de treinamento. Diferentemente de modelos discriminativos, que se concentram em classificar ou prever rótulos a partir de dados, os modelos generativos aprendem a entender a distribuição dos dados de entrada e podem gerar novos exemplos que seguem essa mesma distribuição.\n",
            "\n",
            "Os principais tipos de modelos generativos incluem:\n",
            "\n",
            "1. **Redes Adversariais Generativas (GANs)**: Consistem em duas redes neurais, um gerador e um discriminador, que competem entre si. O gerador cria novos dados, enquanto o discriminador tenta distinguir entre dados reais e gerados. Esse processo de competição leva a uma melhoria contínua na qualidade dos dados gerados.\n",
            "\n",
            "2. **Modelos de Difusão**: Esses modelos geram dados ao reverter um processo de difusão que adiciona ruído aos dados. Eles aprendem a remover esse ruído, permitindo a geração de amostras realistas a partir de ruído aleatório.\n",
            "\n",
            "3. **Modelos Baseados em Transformadores**: Como o GPT (Generative Pre-trained Transformer), que é utilizado para gerar texto. Esses modelos são treinados em grandes corpora de texto e aprendem a prever a próxima palavra em uma sequência, permitindo a criação de textos coerentes e contextualmente relevantes.\n",
            "\n",
            "A IA Generativa tem aplicações em diversas áreas, incluindo arte, design, desenvolvimento de jogos, escrita criativa, e até mesmo na geração de dados sintéticos para treinar outros modelos de IA. No entanto, também levanta questões éticas e de propriedade intelectual, especialmente em relação à autenticidade e ao uso indevido de conteúdos gerados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# Carrega variáveis do .env (contendo GOOGLE_API_KEY)\n",
        "load_dotenv()\n",
        "\n",
        "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "\n",
        "system_prompt = (\n",
        "    \"Você é um cientista da computação. Responda de forma clara, técnica e objetiva. \"\n",
        "    \"Limite a saída a ~300 palavras.\"\n",
        ")\n",
        "user_prompt = \"Explique o que é IA Generativa.\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-flash-latest\",\n",
        "    contents=user_prompt,\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=system_prompt,\n",
        "        temperature=0.4,\n",
        "        max_output_tokens=600,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d0pWacg7jDQ",
        "outputId": "18ec067f-15ba-4f91-bd14-c5488ef69b7d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A **Inteligência Artificial Generativa (IA Generativa)** é um subcampo da IA focado em sistemas capazes de criar conteúdo novo e original (texto, imagens, áudio, código, dados sintéticos) em vez de apenas classificar ou analisar dados existentes.\n",
            "\n",
            "### Arquitetura e Funcionamento\n",
            "\n",
            "O cerne da IA Generativa reside em modelos de aprendizado profundo (Deep Learning) que aprendem a distribuição e a estrutura latente dos dados de treinamento. Os modelos mais proeminentes incluem:\n",
            "\n",
            "1.  **Modelos de Linguagem Grande (LLMs - Large Language Models):** Utilizam a arquitetura **Transformer** (baseada em mecanismos de auto-atenção) para processar sequências de dados. São treinados em vastos *datasets* de texto para prever a próxima palavra, permitindo a geração de narrativas, resumos e código.\n",
            "2.  **Redes Adversariais Generativas (GANs - Generative Adversarial Networks):** Consistem em dois componentes em competição: um **Gerador** (que cria o conteúdo) e um **Discriminador** (que tenta distinguir o conteúdo gerado do conteúdo real). O treinamento ocorre até que o Gerador consiga enganar o Discriminador.\n",
            "3.  **Modelos de Difusão (Diffusion Models):** Atualmente dominantes na geração de imagens. Estes modelos aprendem a reverter um processo de \"ruído\" (adição gradual de ruído Gaussiano aos dados) para reconstruir uma imagem coerente a partir de uma entrada ruidosa ou de um *prompt* textual (utilizando mecanismos como o **CLIP** para alinhamento texto-imagem).\n",
            "\n",
            "### Aplicações Chave\n",
            "\n",
            "A IA Generativa é utilizada em tarefas de *prompt-to-output*, incluindo:\n",
            "\n",
            "*   **Síntese de Mídia:** Geração de imagens fotorrealistas (*text-to-image*), vídeos e áudio sintético (*deepfakes*).\n",
            "*   **Programação:** Geração automática de código e *debugging* (e.g., *copilots*).\n",
            "*   **Processamento de Linguagem Natural (NLP):** Tradução, sumarização, *chatbots* avançados e criação de conteúdo editorial.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "# 1) Carrega variáveis do .env (OPENAI_API_KEY)\n",
        "load_dotenv()\n",
        "\n",
        "# 2) Inicializa o LLM (usa OPENAI_API_KEY do ambiente)\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",   # use \"gpt-5\" só se sua conta tiver acesso\n",
        "    temperature=0.4,\n",
        "    max_tokens=600         # ajuda a manter ~300 palavras\n",
        ")\n",
        "\n",
        "# 3) Define as mensagens (System + User)\n",
        "messages = [\n",
        "    SystemMessage(content=(\n",
        "        \"Você é um cientista da computação. Responda de forma clara, técnica e objetiva. \"\n",
        "        \"Limite a saída a ~300 palavras.\"\n",
        "    )),\n",
        "    HumanMessage(content=\"Explique o que é IA Generativa.\")\n",
        "]\n",
        "\n",
        "# 4) Chama o modelo e imprime\n",
        "resp = llm.invoke(messages)\n",
        "print(resp.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsRFcst47qCr",
        "outputId": "91481c3c-bbf7-48a3-dd98-7fb89d175990"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inteligência Artificial Generativa (IA Generativa) refere-se a um subcampo da inteligência artificial que se concentra na criação de novos conteúdos, como texto, imagens, música e outros tipos de dados. Ao contrário da IA discriminativa, que é projetada para classificar ou prever a partir de dados existentes, a IA generativa utiliza modelos para aprender padrões e características dos dados de treinamento e, em seguida, gerar novas amostras que seguem essas mesmas distribuições.\n",
            "\n",
            "Os modelos de IA generativa mais comuns incluem:\n",
            "\n",
            "1. **Redes Generativas Adversariais (GANs)**: Consistem em duas redes neurais, uma geradora e uma discriminadora, que competem entre si. A rede geradora cria novas amostras, enquanto a discriminadora avalia se as amostras são reais ou falsas. Esse processo de competição melhora continuamente a qualidade das amostras geradas.\n",
            "\n",
            "2. **Modelos de Difusão**: Esses modelos geram dados através de um processo de transformação gradual, onde uma amostra de dados é corrompida por ruído e, em seguida, um modelo aprende a reverter esse processo, gerando novas amostras a partir do ruído.\n",
            "\n",
            "3. **Modelos Baseados em Transformadores**: Como o GPT (Generative Pre-trained Transformer), que são usados para gerar texto coerente e contextualizado. Esses modelos são treinados em grandes volumes de texto e conseguem produzir respostas que imitam a linguagem humana.\n",
            "\n",
            "A IA generativa tem aplicações em diversas áreas, incluindo arte digital, design, geração de texto automatizado, simulações e até mesmo na criação de novos medicamentos. No entanto, também levanta questões éticas, como a potencial criação de desinformação e a propriedade intelectual dos conteúdos gerados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# arquivo: teste_langchain_gemini.py\n",
        "from dotenv import load_dotenv\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage  # SystemMessage opcional (veja abaixo)\n",
        "\n",
        "# 1) Carrega variáveis do .env (GOOGLE_API_KEY)\n",
        "load_dotenv()\n",
        "\n",
        "# 2) Inicializa o LLM Gemini\n",
        "#    Dica: passe o \"system_instruction\" para o papel de sistema (mais robusto com Gemini)\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-flash-latest\",\n",
        "    temperature=0.4,\n",
        "    max_output_tokens=600,\n",
        "    system_instruction=(\n",
        "        \"Você é um cientista da computação. Responda de forma clara, técnica e objetiva. \"\n",
        "        \"Limite a saída a ~300 palavras.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# 3) Define a mensagem do usuário\n",
        "messages = [\n",
        "    HumanMessage(content=\"Explique o que é IA Generativa.\")\n",
        "]\n",
        "\n",
        "# 4) Chama o modelo e imprime\n",
        "resp = llm.invoke(messages)\n",
        "print(resp.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biCKBAYT8HCo",
        "outputId": "c2a205bc-8045-4341-d28d-fc2c91b67328"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Unexpected argument 'system_instruction' provided to ChatGoogleGenerativeAI.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3553: UserWarning: WARNING! system_instruction is not default parameter.\n",
            "                system_instruction was transferred to model_kwargs.\n",
            "                Please confirm that system_instruction is what you intended.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A IA Generativa (ou Inteligência Artificial Generativa) é um subcampo da inteligência artificial focado na criação de **novos conteúdos, dados ou artefatos** que não existiam antes, em vez de apenas classificar ou analisar dados existentes.\n",
            "\n",
            "Em essência, ela ensina as máquinas a serem **criadoras**.\n",
            "\n",
            "## 1. O Que a IA Generativa Faz?\n",
            "\n",
            "A função primária da IA Generativa é **gerar** (produzir) algo que se assemelhe a dados do mundo real nos quais ela foi treinada, mas que seja único e original.\n",
            "\n",
            "Ela pode gerar:\n",
            "\n",
            "| Tipo de Conteúdo | Exemplos de Saída |\n",
            "| :--- | :--- |\n",
            "| **Texto** | Artigos, e-mails, roteiros, poemas, código de programação (ex: ChatGPT, Gemini). |\n",
            "| **Imagens** | Arte digital, fotos realistas a partir de texto, design de produtos (ex: Midjourney, DALL-E, Stable Diffusion). |\n",
            "| **Áudio** | Músicas, vozes sintéticas, efeitos sonoros. |\n",
            "| **Vídeo** | Clipes curtos, animações, vídeos realistas a partir de comandos de texto (ex: Sora). |\n",
            "| **Dados Sintéticos** | Dados de treinamento para outros modelos de IA, simulações. |\n",
            "\n",
            "## 2. Como Ela Funciona? (Os Modelos Chave)\n",
            "\n",
            "A IA Generativa depende de modelos de aprendizado de máquina muito grandes e complexos, treinados em vastas quantidades de dados (texto, imagens, etc.). Os três tipos de arquiteturas mais comuns são:\n",
            "\n",
            "### A. Modelos de Linguagem Grande (LLMs - Large Language Models)\n",
            "\n",
            "* **Foco:** Texto.\n",
            "* **Mecanismo:** Usam a arquitetura **Transformer** (o \"T\" em ChatGPT). Eles preveem a palavra ou o token mais provável que deve vir a seguir em uma sequência, com base em todo o contexto anterior.\n",
            "* **Resultado:** Diálogos coerentes, resumos, traduções e geração de código.\n",
            "\n",
            "### B. Redes Adversariais Generativas (GANs - Generative Adversarial Networks)\n",
            "\n",
            "* **Foco:** Imagens e dados sintéticos.\n",
            "* **Mecanismo:** Consiste em dois modelos que competem:\n",
            "    1. **Gerador:** Cria o conteúdo (ex: uma imagem falsa).\n",
            "    2. **Discriminador:** Tenta determinar se o conteúdo é real (do conjunto de treinamento) ou falso (criado pelo Gerador).\n",
            "* **Resultado:** O Gerador melhora continuamente até conseguir enganar o Discriminador, produzindo resultados extremamente realistas.\n",
            "\n",
            "### C. Modelos de Difusão (Diffusion Models)\n",
            "\n",
            "* **Foco:** Imagens de alta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzmTf6jk8JTr",
        "outputId": "2dbffd68-5b9a-41f0-fa02-b175c8e57981"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langchain                                1.0.5\n",
            "langchain-core                           1.0.4\n",
            "langchain-google-genai                   3.0.2\n",
            "langchain-openai                         1.0.2\n",
            "langchain-text-splitters                 0.3.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Definir o template do prompt\n",
        "template = ChatPromptTemplate(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
        "        (\"human\", \"Hello, how are you doing?\"),\n",
        "        (\"ai\", \"I'm doing well, thanks!\"),\n",
        "        (\"human\", \"{user_input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Criar a chain\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = template | model | output_parser\n",
        "\n",
        "# Invocar a chain\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"name\": \"Bob\",\n",
        "        \"user_input\": \"What is your name?\",\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Prompt value:\")\n",
        "print(template.invoke(\n",
        "    {\n",
        "        \"name\": \"Bob\",\n",
        "        \"user_input\": \"What is your name?\",\n",
        "    }\n",
        "))\n",
        "\n",
        "print(\"\\nResponse:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUUcY7fjmIaS",
        "outputId": "36ea9f1a-3805-426e-a309-be0a53b74bfd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt value:\n",
            "messages=[SystemMessage(content='You are a helpful AI bot. Your name is Bob.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Response:\n",
            "My name is Bob. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Definir o template do prompt\n",
        "template = ChatPromptTemplate(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful Translator. You receive an english text and should replay with translation in portuguese (Brazil). The english text is {english_text}.\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Criar a chain\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = template | model | output_parser\n",
        "\n",
        "# Invocar a chain\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"english_text\": \"Artificial Intelligence is transforming the world.\"\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Prompt value:\")\n",
        "print(template.invoke(\n",
        "    {\n",
        "        \"english_text\": \"Artificial Intelligence is transforming the world.\"\n",
        "    }\n",
        "))\n",
        "\n",
        "print(\"\\nResponse:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZCDJPpJlRS7",
        "outputId": "d3c5a50c-072e-42fc-9a8b-727dfc78112b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt value:\n",
            "messages=[SystemMessage(content='You are a helpful Translator. You receive an english text and should replay with translation in portuguese (Brazil). The english text is Artificial Intelligence is transforming the world..', additional_kwargs={}, response_metadata={})]\n",
            "\n",
            "Response:\n",
            "A Inteligência Artificial está transformando o mundo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gerando um texto generico de post"
      ],
      "metadata": {
        "id": "QZPDAjXD64YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Definir o template do prompt\n",
        "template = ChatPromptTemplate(\n",
        "    [\n",
        "        (\"system\", \"Escreva um post, no estilo de blog de tecnologia, sobre o topico {topico_especifico}. O post deve ser informativo e gerar engajamento. O tamanho maximo do post e 500 palavras\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Criar a chain\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = template | model | output_parser\n",
        "\n",
        "# Invocar a chain\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"topico_especifico\": \"Inteligencia Artificial\"\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"\\nResponse:\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "0RFgZi9y5xKh",
        "outputId": "350a5e98-64d9-4485-e7cb-7a5039098d47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Response:\n",
            "Desde o surgimento da inteligência artificial (IA), muitas possibilidades foram abertas para transformar nossa maneira de interagir com a tecnologia e o mundo ao nosso redor. A IA, que permite que as máquinas aprendam e ajam de forma autônoma, tem sido integrada em uma variedade de serviços e produtos, desde assistentes virtuais até carros autônomos.\n",
            "\n",
            "Um exemplo claro da eficiência da IA é o reconhecimento de voz. Atualmente, vemos assistentes virtuais como a Alexa, da Amazon, e a Siri, da Apple, que conseguem entender nossos comandos e responder de forma eficaz, sempre aprendendo e se adaptando às nossas preferências. Além disso, a IA tem sido utilizada em diagnósticos médicos, identificação de fraudes em transações financeiras, previsões meteorológicas e muito mais.\n",
            "\n",
            "No entanto, é importante ressaltar que, apesar de seus benefícios, a IA também levanta questões éticas e preocupações sobre privacidade e segurança. O uso de IA em aplicações como reconhecimento facial e análise de dados pessoais pode suscitar debates sobre vigilância em massa e proteção de informações sensíveis.\n",
            "\n",
            "Com o avanço da IA, é fundamental que haja um debate aberto e transparente sobre suas aplicações e limitações. É preciso desenvolver políticas e regulamentações que garantam que a IA seja utilizada de forma ética e responsável, respeitando os direitos individuais e promovendo a igualdade e a justiça em sua implementação.\n",
            "\n",
            "Além disso, é importante destacar o papel da IA na criação de soluções para os desafios enfrentados pela sociedade, como a mudança climática, a pobreza e a saúde pública. A IA pode ser uma poderosa ferramenta para analisar grandes conjuntos de dados e identificar padrões que ajudem a prever e mitigar problemas em diversas áreas.\n",
            "\n",
            "Como usuários e consumidores, também temos a responsabilidade de entender como a IA funciona e como ela impacta nossas vidas. Devemos nos manter informados sobre as últimas tendências e desenvolvimentos em IA, para podermos aproveitar seus benefícios e nos proteger de possíveis consequências negativas.\n",
            "\n",
            "Em resumo, a inteligência artificial está transformando o mundo em que vivemos, proporcionando inúmeras oportunidades e desafios. É essencial que continuemos a explorar seus limites e possibilidades, buscando sempre utilizar essa tecnologia de forma ética e responsável. Juntos, podemos moldar um futuro em que a IA seja uma aliada na busca por um mundo melhor e mais inclusivo para todos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fazendo um resumo de um documento pdf"
      ],
      "metadata": {
        "id": "nNG9Pahg_2fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-text-splitters langchain-openai sentence-transformers faiss-cpu pypdf"
      ],
      "metadata": {
        "id": "J7jNs99D50E_",
        "outputId": "48f79dc5-6e66-400d-ca88-3ce3601fa6ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (0.3.11)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.2.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters) (1.0.4)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.4.41)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (2.11.10)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (8.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain-text-splitters) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.2.0-py3-none-any.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.6/326.6 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf, faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0 pypdf-6.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "id": "azNbT67-9LlA",
        "outputId": "daf4bb15-42fb-45f9-d627-f1680617f103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.4)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.41)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-text-splitters-1.0.0 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              },
              "id": "804aa06141594a5cbbaff275899e7da4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "from typing import List\n",
        "\n",
        "# 1) Carregamento do PDF\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# 2) Chunking\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 3) Embeddings e Vetorstore (FAISS)\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "# (alternativa OpenAI: from langchain_openai import OpenAIEmbeddings)\n",
        "\n",
        "# 4) LLM e Prompt\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ],
      "metadata": {
        "id": "8P5YXWfq8wwu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf_docs(pdf_path: str):\n",
        "    \"\"\"Carrega páginas do PDF como Document objects do LangChain.\"\"\"\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    docs = loader.load()  # lista de Documents, um por página\n",
        "    return docs\n",
        "\n",
        "\n",
        "def chunk_documents(docs, chunk_size=1200, chunk_overlap=200):\n",
        "    \"\"\"Quebra documentos em chunks com índices para rastreabilidade.\"\"\"\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        add_start_index=True,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
        "    )\n",
        "    return splitter.split_documents(docs)\n",
        "\n",
        "\n",
        "def build_vectorstore(chunks):\n",
        "    \"\"\"Gera embeddings e constrói um FAISS local.\"\"\"\n",
        "    # Embedding leve, gratuito e robusto:\n",
        "    embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    # (Alternativa OpenAI — pago):\n",
        "    # embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "    vs = FAISS.from_documents(chunks, embedder)\n",
        "    return vs\n",
        "\n",
        "\n",
        "def make_retriever(vs, k=6):\n",
        "    \"\"\"Cria um retriever (Top-k) em cima do índice FAISS.\"\"\"\n",
        "    return vs.as_retriever(search_kwargs={\"k\": k})\n",
        "\n",
        "\n",
        "def build_llm(model_name: str = \"gpt-4o-mini\", temperature: float = 0.2):\n",
        "    \"\"\"Instancia o LLM. Padrão: OpenAI (gpt-4o-mini).\"\"\"\n",
        "    # OpenAI\n",
        "    return ChatOpenAI(model=model_name, temperature=temperature)\n",
        "    # Gemini (alternativa):\n",
        "    # return ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=temperature)\n",
        "\n",
        "\n",
        "def format_docs(docs: List) -> str:\n",
        "    \"\"\"Concatena chunks em um único contexto com metadados de página/índice.\"\"\"\n",
        "    out = []\n",
        "    for i, d in enumerate(docs, start=1):\n",
        "        page = d.metadata.get(\"page\", \"NA\")\n",
        "        start = d.metadata.get(\"start_index\", \"NA\")\n",
        "        out.append(f\"[Chunk {i} | page {page} | start {start}]\\n{d.page_content}\")\n",
        "    return \"\\n\\n\".join(out)\n",
        "\n",
        "\n",
        "def build_summary_chain(llm):\n",
        "    \"\"\"\n",
        "    Cadeia LCEL:\n",
        "      input: {\"question\": ..., \"context\": ...}\n",
        "      output: resposta/summary focado na pergunta, citando apenas o contexto.\n",
        "    \"\"\"\n",
        "    system_msg = (\n",
        "        \"Você é um assistente que responde SOMENTE com base no CONTEXTO fornecido.\\n\"\n",
        "        \"Se algo não estiver no contexto, diga que não há evidências no material recuperado.\\n\"\n",
        "        \"Produza um resumo claro, fiel e objetivo, e destaque os pontos-chave.\\n\"\n",
        "        \"Idioma: português.\"\n",
        "    )\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_msg),\n",
        "            (\n",
        "                \"human\",\n",
        "                \"Pergunta do usuário:\\n{question}\\n\\n\"\n",
        "                \"Contexto (chunks recuperados do PDF):\\n{context}\\n\\n\"\n",
        "                \"Instruções:\\n\"\n",
        "                \"- Faça um resumo focado na pergunta acima, citando apenas o contexto.\\n\"\n",
        "                \"- Liste tópicos-chave em bullet points.\\n\"\n",
        "                \"- Se houver limitações, seja explícito.\\n\"\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    chain = (\n",
        "        {\"question\": RunnablePassthrough(), \"context\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | llm\n",
        "    )\n",
        "    return chain\n",
        "\n",
        "\n",
        "def query_and_summarize(pdf_path: str, question: str, k: int = 6):\n",
        "    # 1) PDF -> docs\n",
        "    docs = load_pdf_docs(pdf_path)\n",
        "\n",
        "    # 2) chunking\n",
        "    chunks = chunk_documents(docs)\n",
        "\n",
        "    # 3) embeddings + index\n",
        "    vs = build_vectorstore(chunks)\n",
        "\n",
        "    # 4) retrieval\n",
        "    retriever = make_retriever(vs, k=k)\n",
        "    relevant_docs = retriever.invoke(question)\n",
        "\n",
        "    # 5) summary via LLM baseado APENAS nos chunks recuperados\n",
        "    llm = build_llm()\n",
        "    chain = build_summary_chain(llm)\n",
        "    context_text = format_docs(relevant_docs)\n",
        "\n",
        "    # Executa a cadeia:\n",
        "    resp = chain.invoke({\"question\": question, \"context\": context_text})\n",
        "\n",
        "    return {\n",
        "        \"matches\": relevant_docs,\n",
        "        \"summary\": resp.content if hasattr(resp, \"content\") else str(resp),\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    load_dotenv()\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"PDF RAG + Summary (LangChain 1.0 style)\")\n",
        "    parser.add_argument(\"--pdf\", required=True, help=\"Caminho para o arquivo PDF\")\n",
        "    parser.add_argument(\"--query\", required=True, help=\"Pergunta do usuário para orientar o resumo\")\n",
        "    parser.add_argument(\"--k\", type=int, default=6, help=\"Quantidade de chunks a recuperar (top-k)\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if not os.path.exists(args.pdf):\n",
        "        raise FileNotFoundError(f\"PDF não encontrado: {args.pdf}\")\n",
        "\n",
        "    result = query_and_summarize(args.pdf, args.query, k=args.k)\n",
        "\n",
        "    print(\"\\n================= CHUNKS RECUPERADOS =================\")\n",
        "    for i, d in enumerate(result[\"matches\"], start=1):\n",
        "        page = d.metadata.get(\"page\", \"NA\")\n",
        "        print(f\"\\n--- Chunk {i} (page {page}) ---\\n{d.page_content[:800]}{'...' if len(d.page_content) > 800 else ''}\")\n",
        "\n",
        "    print(\"\\n==================== RESUMO (LLM) ====================\")\n",
        "    print(result[\"summary\"])\n",
        "    print(\"\\n======================================================\\n\")\n"
      ],
      "metadata": {
        "id": "Li7FKhFK9ntJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pdf_summary(path_pdf: str, my_query: str, my_k: int = 6):\n",
        "    \"\"\"\n",
        "    Executa todo o pipeline de recuperação e resumo de um PDF com LangChain 1.0.\n",
        "\n",
        "    Args:\n",
        "        path_pdf (str): Caminho completo do arquivo PDF a ser analisado.\n",
        "        my_query (str): Pergunta que orienta a busca e o resumo.\n",
        "        my_k (int): Quantidade de chunks mais relevantes a recuperar (default=6).\n",
        "\n",
        "    Returns:\n",
        "        dict: Contém 'matches' (chunks relevantes) e 'summary' (texto resumido).\n",
        "    \"\"\"\n",
        "    import os\n",
        "\n",
        "    if not os.path.exists(path_pdf):\n",
        "        raise FileNotFoundError(f\"PDF não encontrado: {path_pdf}\")\n",
        "\n",
        "    result = query_and_summarize(path_pdf, my_query, k=my_k)\n",
        "\n",
        "    print(\"\\n================= CHUNKS RECUPERADOS =================\")\n",
        "    for i, d in enumerate(result[\"matches\"], start=1):\n",
        "        page = d.metadata.get(\"page\", \"NA\")\n",
        "        print(f\"\\n--- Chunk {i} (page {page}) ---\\n{d.page_content[:800]}{'...' if len(d.page_content) > 800 else ''}\")\n",
        "\n",
        "    print(\"\\n==================== RESUMO (LLM) ====================\")\n",
        "    print(result[\"summary\"])\n",
        "    print(\"\\n======================================================\\n\")\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "TVmTf1Gg9u3Q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso\n",
        "pdf_path = \"NotaUFPI.pdf\"\n",
        "consulta = \"Você pode resumir o conteúdo desse documento\"\n",
        "resultado = run_pdf_summary(pdf_path, consulta, my_k=5)"
      ],
      "metadata": {
        "id": "T_9LVAmA_JBc",
        "outputId": "6b1dbb7f-27dc-435a-d358-1974a28312fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f06f45df05d5494a9080688188b2bc67",
            "e5804b127287430bb299985b5bed57c5",
            "e34a914029d242b69622a3cd30eeb497",
            "5ab98b14af82489085f4b7c0326310c9",
            "cd63525fc8044e00b86191cc79169415",
            "97763c5eece346559ccb8c326f1b341e",
            "1dccaa70f46049768f6b063b50de9fa4",
            "b92fb48889c743798bd0a4ee4aa4414b",
            "2ba5b95ccfda425e92f1eaa337dfd017",
            "b259c5dca5ed4ae1b7b64ff5a7b06e1e",
            "c3dd0dce346345ceae59bf8a6053dce9",
            "f37f1a5cf6cc46daa4512afe839757bd",
            "b9c41eff0b124657ad8da514569c8ebd",
            "2a5189abf939478da10ca0655a2af099",
            "48d09eb41ca44f5f9fc350cf1afc20ab",
            "f585481578da485a8d4235488ac85b90",
            "7343bb5801564eee9b1736257c290976",
            "a46af50ed8a34630b073c5cf3e4b0fd0",
            "ee18ddf136774835a07b6be707b366ad",
            "17a2844f96924dba9bf14bbf5005b246",
            "50b6bc59493546b5bad19f883ffc91df",
            "4f80ec70c77541cc95b0c3f9ee2c1505",
            "3bfce0d9e9e847d29078ce565ad23922",
            "32880ee8b6804b3caa5f191528d29612",
            "9b27f76b13f146c6ac86abfa28762358",
            "d6447f6a664f44f5b78b25f6fc4b44b0",
            "3ea4417cc97546c4838d54d2eac303f6",
            "62cfa95ad76e423ba2432a32286d0bee",
            "f3b1b27389904eeb83b3d934b87b37e0",
            "b0f90c0f9eb1462181dddba637c1087a",
            "b405253f4e2647bd896d22388ad27c87",
            "0c4eb96536d4444f8d68ed926d8e1ee5",
            "f07a2131c0e64b7eb7f0884e7d6158c6",
            "ba7693d943aa4513ae552aa12d2a8f17",
            "a485479135aa46418dd79e70783183e4",
            "d2988dcc9f0f4457a3d8bf9b87cfe9ee",
            "69405dc704a44e6398433ea781d7a55b",
            "36e4929ef48742ccb1bf3722c0d37f5b",
            "66d3a6082c6b4324bd762371b6bd6bb1",
            "be1eac8380c1458ebea1da92dfcaa3e1",
            "b1bd49744c9f43a8bcf0e27468e3995a",
            "116215276ab046ce814b88513337030c",
            "4d90b298065a4f6f9c49146e6392fc61",
            "c90a8249130a4935a163298babe944d4",
            "a0e57dd8e005448b8ef36c79970cd78d",
            "364d9ee4f66049069ec854afd9357392",
            "9dd56deb408f4bbd8353081685a12712",
            "65fd29dad3584f1caa651255f5dfd697",
            "acaadd73d1d74466b7a05e800f43571e",
            "ba941635894d4b858135ec284e6fc58c",
            "e4f78eb7a53f44cbaec8d2f7f73fb22c",
            "f018d87990174833bfebfa1adbdeaeb7",
            "8744914feb8d4c768f460d8d91d684fd",
            "7998e20dae794c5d8dae75ccff6b9078",
            "e6c952816218486188ceb4ebe245c25f",
            "99a745b4289c462889fd3d51264e60ff",
            "3f23d78dfb724dbeb78f68b82d6561f6",
            "a23c5cf5127d48f784cce74934185d00",
            "2b130f4846ad4e888d7ebc41cf2288ef",
            "a76d24e3be314b43b56a817800156586",
            "d03e2d2910ae49dba22fd01e84115e75",
            "d55ee68bf0224171be7c509e448f068f",
            "a32c9ad027d54306a73c60374215a852",
            "431decc0992c4624adf310d0676a8621",
            "11f1149ad4204805bb970240d6ac24ff",
            "9b1da1eb0082446cb8247c66d2749a43",
            "09d4903ed1d84404a59615881127e7d7",
            "eadc47586e07470a820ac75e147afc06",
            "6214db4941bd4b55818100222c2e8a6c",
            "85c6c71d20c44a7690dae3ec526e8b8c",
            "a11c4ea3dac64d19b91a164c04d45e53",
            "d02822ba8dc24f198474246b84c3f4fa",
            "9ea09ce26bb9478bbfc4f5aed204e380",
            "c71f8b705c7a4000bf6ee800c6382f2f",
            "a6e389fc120e40f7895fc7bb013aacb1",
            "e39d63a38f3241d4994213cab0406f2d",
            "a80b74b4464e4114a30c50395836cb8c",
            "2282f5fb1fa04877a31fc8832e43efff",
            "029f5d8761624ff89051531d6f526224",
            "893ca956196344af83fceb64a40771af",
            "253c60997c2e4c96a9e9709b4c72737c",
            "8aae587d41fe4d4ab88b6a7e992be7ee",
            "b180a4c3085842c68f6dc2206c1dfb5d",
            "dbb654529c9047fdb3f625ccc802e5eb",
            "1c3e8d9ada90427889f54cb773f296a4",
            "2c1ffa2d276e44089b491ff20bc7280c",
            "30f24bbcb904425289536ab8e5f99435",
            "9edfb44b1f6241a69136ad0edf4cc6f6",
            "5b9183dbd68445bdb5f0586c8bba6cd2",
            "b538f240eb7846b38d3f440e4b1353ba",
            "9785f63902c0468a97dac74d7a71146a",
            "a81cbc7c845c4d86a60abd31898a08d5",
            "47dd3f6173f5450aacfcae6deb50571e",
            "85669f85f6014139b1246bd589e83411",
            "1030750b5be444e99cfc02540bbbbad1",
            "ee200237013c42deb26193a970ee6ec1",
            "ddae935e17e04a5396e0601c3819b199",
            "c7232a98f6af4a35b5136919be27c91b",
            "d4cb78d1c0634c27ba97afe8ec81674e",
            "229396b1918b4825a79ba6a29b8135d0",
            "56ff3fd4f23c4e51bb86275aa4267ef5",
            "a28a1eb640324e649a4daa7c22c72ac0",
            "c57aa71b0c2849949b959e58e8861701",
            "dbc60765e0d64525b7c19c495ffc2e5d",
            "3c52471ed3af41da91fc6d5bd810f877",
            "8f24a688b3b14fe492f5abc2052e377c",
            "554085c44c4b415bb741af14694a9f97",
            "2c00cdc92a8c427a8ada8064b20b489e",
            "5bf60848b5df4cef8c0b9e0625a43efc",
            "f3854647477c4982a19bc15c0484a968",
            "7407faff56da4259834fbe87890bdc70",
            "408cd034f7e04bd8857cb8da6fcd4114",
            "5f9fad1dca0445d6a52990055f567f4b",
            "c8d367f33f6549458068b2845bade3bd",
            "6faaafaf28d5447abe54c6111b53660d",
            "e7a692994c214e319c05021d1d225c9c",
            "d00614d7a8a34f608f4b4c093fb82450",
            "3c8c29b4aaa44c15afcc2145502a1584",
            "fb5a27d0fd14432780583d0247b2bed4",
            "01457259f59a452383ec1d8889b24aac",
            "0933b0c3953242e98d3bfc831bd1b875"
          ]
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 17 0 (offset 0)\n",
            "/tmp/ipython-input-4193047823.py:22: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f06f45df05d5494a9080688188b2bc67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f37f1a5cf6cc46daa4512afe839757bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bfce0d9e9e847d29078ce565ad23922"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba7693d943aa4513ae552aa12d2a8f17"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0e57dd8e005448b8ef36c79970cd78d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99a745b4289c462889fd3d51264e60ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09d4903ed1d84404a59615881127e7d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2282f5fb1fa04877a31fc8832e43efff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b9183dbd68445bdb5f0586c8bba6cd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "229396b1918b4825a79ba6a29b8135d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7407faff56da4259834fbe87890bdc70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================= CHUNKS RECUPERADOS =================\n",
            "\n",
            "--- Chunk 1 (page 1) ---\n",
            "acompanhar o andamento das ações e deliberar sobre as medidas necessárias à normalização \n",
            "completa dos serviços.\n",
            "Em razão do processo de estabilização da rede e do período de observação técnica, as \n",
            "atividades administrativas e pedagógicas permanecerão suspensas nesta segunda-feira, 20 de \n",
            "outubro. Os sistemas institucionais e o datacenter da UFPI estão em fase de veri ﬁcação e não \n",
            "podem ser recarregados de uma só vez, exigindo acompanhamento gradual para garantir a \n",
            "segurança e a integridade das informações.\n",
            "Os trabalhos continuam sem interrupção, com o empenho conjunto das equipes administrativas \n",
            "e de apoio, assegurando a continuidade dos serviços essenciais à comunidade universitária.\n",
            "Teresina (PI), 19 de outubro de 2025.\n",
            "Universidade Federal do Piauí - UFPI\n",
            "\n",
            "--- Chunk 2 (page 1) ---\n",
            "A Reitoria mantém contato direto com o Governador Rafael Fonteles, articulando apoio junto ao \n",
            "Corpo de Bombeiros Militar, à Defesa Civil e à Secretaria de Segurança Pública do Estado, que \n",
            "acompanham a situação e prestam suporte às equipes da Universidade.\n",
            "A Reitora Nadir do Nascimento Nogueira vistoriou as áreas afetadas, incluindo o local dani ﬁcado \n",
            "no sistema elétrico, a Residência Estudantil e outros setores da UFPI, em companhia do Pró-\n",
            "Reitor de Planejamento e Orçamento (PROPLAN) e da Prefeita Universitária (PREUNI), \n",
            "acompanhando de perto as providências adotadas pelas equipes administrativas.\n",
            "Toda a Administração Superior da UFPI está mobilizada e atuando de forma integrada para \n",
            "mitigar os impactos da pane elétrica e restabelecer plenamente as condições de funcionamento \n",
            "da Univ...\n",
            "\n",
            "--- Chunk 3 (page 0) ---\n",
            "NOTA À COMUNIDADE UNIVERSITÁRIA\n",
            "A Universidade Federal do Piauí (UFPI) informa que, com a troca dos cabos dani ﬁcados, o \n",
            "fornecimento de energia elétrica foi restabelecido no Campus Ministro Petrônio Portella. A \n",
            "Instituição encontra-se agora em fase de observação do comportamento dos equipamentos \n",
            "elétricos, para veri ﬁcar a estabilidade do sistema e identi ﬁcar eventuais ocorrências nas \n",
            "instalações.\n",
            "A situação está sendo acompanhada pela Prefeitura Universitária (PREUNI), que atuou de forma \n",
            "permanente durante o período crítico, coordenando os serviços de manutenção, abastecimento e \n",
            "suporte técnico. A Equatorial Piauí realizou a religação da rede quando acionada pelas equipes \n",
            "da Universidade.\n",
            "Entre as ações emergenciais realizadas, destacam-se o abastecimento de água por meio de \n",
            "car...\n",
            "\n",
            "--- Chunk 4 (page 0) ---\n",
            "gerador. O Hospital Universitário da UFPI (HU-UFPI) também colaborou, armazenando amostras \n",
            "biológicas e prestando apoio técnico às equipes de campo, assegurando a preservação de \n",
            "materiais sensíveis. A Fundação de Apoio à Pesquisa, Ensino e Extensão (FADEX) contribuiu \n",
            "agilizando os procedimentos necessários à contratação de geradores para atendimento das \n",
            "demandas emergenciais.\n",
            "A Pró-Reitoria de Administração (PRAD) realizou a comunicação com as empresas terceirizadas, \n",
            "orientando a adoção de medidas adequadas ao contexto emergencial e garantindo a \n",
            "continuidade dos serviços essenciais.\n",
            "\n",
            "==================== RESUMO (LLM) ====================\n",
            "Resumo do documento:\n",
            "\n",
            "A Universidade Federal do Piauí (UFPI) está enfrentando um processo de estabilização da rede elétrica após uma pane, que resultou na suspensão das atividades administrativas e pedagógicas em 20 de outubro de 2025. A Reitoria está em contato com autoridades estaduais para garantir suporte e a normalização dos serviços. As equipes administrativas estão mobilizadas para mitigar os impactos e assegurar a continuidade dos serviços essenciais.\n",
            "\n",
            "Tópicos-chave:\n",
            "- Suspensão das atividades administrativas e pedagógicas devido à estabilização da rede elétrica.\n",
            "- Acompanhamento da situação pela Reitoria em contato com o Governador e órgãos de segurança.\n",
            "- Vistorias realizadas pela Reitora nas áreas afetadas.\n",
            "- Restabelecimento do fornecimento de energia elétrica após troca de cabos danificados.\n",
            "- Ações emergenciais incluem abastecimento de água e assistência a estudantes.\n",
            "- Colaboração do Hospital Universitário e da Fundação de Apoio à Pesquisa para atender demandas emergenciais.\n",
            "- Comunicação com empresas terceirizadas para garantir a continuidade dos serviços essenciais.\n",
            "\n",
            "======================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ta8F_MYh_lN-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}